---
title: "ANEXO TFG - `Modelos estadísticos para el análisis financiero'"
author: "Belén Rodríguez Llorente"
date: "04-06-2024"
output: 
  html_document:
    fig_caption: yes
    latex_engine: xelatex
    number_sections: yes
    toc: true
---

El fichero riesgocrediticio.csv recoge información sobre una muestra aleatoria de referencia y de rendimiento de préstamos para 5,960 préstamos. Las variables son:

BAD: Variable binaria 1 = individuo con préstamo incumplido o pago con moratoria; 0 = individuo que paga su deuda y no tiene registro negativo

LOAN: Cantidad que el individuo solicita como préstamo, es decir, el monto de solicitud de préstamo

MORTDUE: Monto adeudado de la hipoteca existente

VALUE: Valor actual del bien o propiedad

REASON: DebtCon = consolidación de la deuda; HomeImp = mejoras para el hogar

JOB: Ocupación o profesión

YOJ: Años en su trabajo actual

DEROG: Número de informes importantes derogados 

DELINQ: Número de líneas de crédito morosas

CLAGE: Antiguedad en meses de la línea de crédito más antigua del prestatario

NINQ:Número de consultas crediticas recientes (nº de líneas de crédito que ha abierto en los últimos 6 meses)

CLNO: Número de líneas de crédito que tiene el prestatario

DEBTINC: relación entre la deuda y el ingreso del prestatario , se calcula diividiendo los pagos mensuales totales entre sus ingresos mensuales


El objetivo es analizar y explicar según un modelo estadístico adecuado los factores que intervienen en que un individuo sea moroso o no. Como se observa BAD es una variable binaria que indica si un solicitante finalmente incurrió en incumplimiento en alguna entidad bancaria. Y por muestreo rápido este resultado adverso se produjo en 1.189 casos (20%) del total de la muestra.

Instalemos todas las librerías a usar:
```{r set up,warning=FALSE, message=FALSE}
library(dplyr)
library(ggplot2)
library(rsample)
library(caret)
library(vip)
library(broom)
library(tidyverse)
library(nnet)
library(pROC)
library(gridExtra)
```

# Lectura de datos.

Nótese que el fichero tiene encabezados, por lo que se selecciona "Yes" en la opción Heading. Además, este conjunto de datos tiene tres variables cualitativas (de tipo caracter): BAD, REASON y JOB. Queremos que la clase de estos objetos sea Factor, por lo que marcamos la casilla de "Strings as Factors" durante la lectura.

```{r}
riesgocrediticio <- read.csv("C:/Users/belen/OneDrive/Escritorio/COSAS TFG/riesgocrediticio.csv",na.strings = c("", "NA"),stringsAsFactors=TRUE)

View(riesgocrediticio)
```

OBSERVACIÓN:  Aunque BAD sea una variable binaria, pues está codificada como 0 y 1, sigue siendo una variable cualitativa o categórica. Esto se debe a que los valores numéricos representan categorías, en lugar de una magnitud numérica continua.
Aunque no necesitamos convertirla en un factor, sigue siendo importante reconocer que representa una categoría y tratarla como tal en el análisis.

NOTA: Si no se hubiera clicado en la casilla mencionada al importar los datos, la clase de estas variables sería char. Para convertir manualmente las variables de clase char a clase Factor, se puede usar el siguiente código:
```{r}
riesgocrediticio$BAD=as.factor(riesgocrediticio$BAD)
riesgocrediticio$REASON=as.factor(riesgocrediticio$REASON)
riesgocrediticio$JOB=as.factor(riesgocrediticio$JOB)
```

Ahora que tenemos nuestros datos, exploremoslos. Lo primero obtengamos una vista general de ellos utilizando la función glimpse() y del comando summary() para representar estadísticas básicas sobre las variables.
```{r}
glimpse(riesgocrediticio)
```


```{r}
summary(riesgocrediticio)
```

Podemos observar que nuestra base de datos contiene 5960 observaciones y 13 variables (10 cuantitativas y 3 cualitativas).Los resultados muestran que tenemos una cantidad significativa de datos faltantes, que en el conteo se representan como NA. Necesitamos abordar este problema pues la regresión logística no es adecuada para manejar datos faltantes. La regresión se utiliza para modelar el tamaño y la fuerza de las relaciones numéricas, y con ausencia de datos no podemos modelar. 

# Outliers

```{r}
boxplot(riesgocrediticio$CLAGE, horizontal = T, xlab = "CLAGE")
boxplot(riesgocrediticio$VALUE, horizontal = T, xlab = "VALUE")
boxplot(riesgocrediticio$LOAN, horizontal = T, xlab = "LOAN")
boxplot(riesgocrediticio$MORTDUE, horizontal = T, xlab = "MORTDUE")
boxplot(riesgocrediticio$DEBTINC, horizontal = T, xlab = "DEBTINC")
boxplot(riesgocrediticio$YOJ, horizontal = T, xlab = "YOJ")
boxplot(riesgocrediticio$DEROG, horizontal = T, xlab = "DEROG")
boxplot(riesgocrediticio$DELINQ, horizontal = T, xlab = "DELINQ")
boxplot(riesgocrediticio$CLNO, horizontal = T, xlab = "CLNO")
boxplot(riesgocrediticio$NINQ, horizontal = T, xlab = "NINQ")
```



# Datos faltantes, NA's

Vamos a estudiar como solventar la presencia de NA's en nuestra base de datos. Representémosla mediante un 

```{r}
# Crear un resumen de las NA por columna
na_summary <- colSums(is.na(riesgocrediticio))

# Crear un data frame con los nombres de las columnas y el número de NA
na_df <- data.frame(column = names(na_summary), na_count = na_summary)

# Plot del heatmap
ggplot(na_df, aes(x = column, y = 1, fill = na_count)) +
  geom_tile() +
  scale_fill_gradient(low = "blue", high = "red") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust = 1)) +
  labs(title = "Heatmap de valores nulos en cada columna", y = NULL)

```


En las variables cualitativas el primer caso se trata de una variable dicotómica o binaria, pero la variable JOB tiene 6 categorías, entonces se usan 6-1=5 variables ficticias o dummy para describirla adecuadamente mediante variables dicotómicas. Por defecto lo codifica por orden alfabético pero como no es una clasificación de orden, no importa. Vemos que los 1 de las variables dummy no se solapan, quedando las categorías completamente separadas. 

```{r}
riesgocrediticio %>%
 select(JOB) %>%
 table(exclude=NULL) %>%
 prop.table()
```

Aunque en este caso el porcentaje de NA's para las variables categóricas es bastante bajo podemos modelar los datos faltantes añadiendo una salida que sustituya el valor NA, por ejemplo:"UNK" del inglés unknown, desconocido.
Esto se hace para compensar el hecho de que la regresión logística no puede manejar valores NA.
```{r}
riesgocrediticio <- riesgocrediticio %>%
   mutate(JOB = as.character(JOB)) %>%
   mutate(JOB = as.factor(ifelse(is.na(JOB), 'UNK', JOB)))%>%
   mutate(REASON = as.character(REASON)) %>%
   mutate(REASON = as.factor(ifelse(is.na(REASON), 'UNK', REASON)))

riesgocrediticio %>%
 keep(is.factor) %>%
 summary()
```
Esto de manera teórica es muy interesante si también se diesen unas condiciones con mayor representación de NA's. Pero en nuestro caso, omitiremos lo realizado y veamos que al eliminar los datos faltantes de estas dos columnas el número de observaciones se reduce de manera casi insignificante. 


```{r}
data <- riesgocrediticio[complete.cases(riesgocrediticio[c("JOB", "REASON")]), ]
dim(data)
summary(data)
```
Ahora hemos resuelto el problema de los valores faltantes de las variables categóricas.

Respecto a las variables continuas podemos ver que la varible "DEBTINC" es la que presenta una mayor cantidad significante de datos faltantes.
Estudiemos entonces la posible eliminación de dicha variable para nuestro estudio.

```{r}
na_debtinc=sum(is.na(data$DEBTINC))
na_debtinc
```

```{r}
prop_na=na_debtinc/nrow(data)
prop_na
```
Puesto que nos faltan más del 20% (~21.26%)de los datos en esa variable, estudiemos la correlación respecto al resto de variables cuantitativas.
```{r}
datos_DEBTINC=nrow(data)-na_debtinc
datos_DEBTINC
datos=na.omit(data) #base de datos habiendo eliminado todas las observaciones de las que no tenemos datos en la columna de la variable DEBTINC
cor(datos[,-c(1,5,6)], datos$DEBTINC)
heatmap(abs(cor(datos[,-c(1,5,6)])),scale="none")
```


Tras analizar los resultados numéricos y el mapa de calor en cuanto a la variable DEBTINC, podemos concluir que su correlación con el resto de variables es muy baja. Para no erradicarla del estudio hagamos dos modelos uno con este variable y otro sin ella.

```{r}
# Configurar ventana grafica 2x2
par(mfrow = c(2, 2))

# Histograma de MORTDUE
hist(datos$MORTDUE, breaks = 30, col = "blue", border = "black",
     main = "Distribución de MORTDUE",
     xlab = "Valor de MORTDUE",
     ylab = "Frecuencia")

# Histograma de VALUE
hist(datos$VALUE, breaks = 30, col = "green", border = "black",
     main = "Distribución de VALUE",
     xlab = "Valor de VALUE",
     ylab = "Frecuencia")

# Histograma de YOJ
hist(datos$YOJ, breaks = 30, col = "red", border = "black",
     main = "Distribución de YOJ",
     xlab = "Valor de YOJ",
     ylab = "Frecuencia")

# Histograma de CLAGE
hist(datos$CLAGE, breaks = 30, col = "orange", border = "black",
     main = "Distribución de CLAGE",
     xlab = "Valor de CLAGE",
     ylab = "Frecuencia")
```


```{r}
# Grafico de barras para DEROG
p1 = ggplot(datos, aes(x = factor(DEROG))) +
  geom_bar(fill = "blue", color = "black") +
  labs(title = "Gráfico de barra de DEROG Values",
       x = "Valores de DEROG",
       y = "Frequencia") +
  theme_minimal()

# Grafico de barras para DELINQ
p2 = ggplot(datos, aes(x = factor(DELINQ))) +
  geom_bar(fill = "green", color = "black") +
  labs(title = "Gráfico de barra de DELINQ Values",
       x = "Valores de DELINQ",
       y = "Frequencia") +
  theme_minimal()

# Grafico de barras para NINQ
p3 = ggplot(datos, aes(x = factor(NINQ))) +
  geom_bar(fill = "red", color = "black") +
  labs(title = "Gráfico de barra de NINQ Values",
       x = "Valores de NINQ",
       y = "Frequencia") +
  theme_minimal()

# Grafico de barras para CLNO
p4 =ggplot(datos, aes(x = factor(CLNO))) +
  geom_bar(fill = "orange", color = "black") +
  labs(title = "Gráfico de barra de CLNO Values",
       x = "Valores de CLNO",
       y = "Frequencia") +
  theme_minimal()

# Organizar los graficos en un diseño 2x2
grid.arrange(p1, p2, p3, p4, ncol = 2)
```

```{r}
# Calcular la mediana de DEROG
mediana_DEROG <- median(datos$DEROG, na.rm = TRUE)

# Imputar los valores faltantes de DEROG con la mediana
datos$DEROG[is.na(datos$DEROG)] <- mediana_DEROG


# Calcular la mediana de DELINQ
mediana_DELINQ <- median(datos$DELINQ, na.rm = TRUE)

# Imputar los valores faltantes de DELINQ con la mediana
datos$DELINQ[is.na(datos$DELINQ)] <- mediana_DELINQ


# Calcular la mediana de NINQ
mediana_NINQ <- median(datos$NINQ, na.rm = TRUE)

# Imputar los valores faltantes de NINQ con la mediana
datos$NINQ[is.na(datos$NINQ)] <- mediana_NINQ

# Calcular la moda de CLNO
moda_CLNO <- datos %>%
  filter(!is.na(CLNO)) %>%
  count(CLNO) %>%
  arrange(desc(n)) %>%
  slice(1) %>%
  pull(CLNO)

# Imputar los valores faltantes de CLNO con la moda
datos$CLNO[is.na(datos$CLNO)] <- moda_CLNO
```


```{r}
sapply(datos, function(x) sum(is.na(x)))
```

Al tratar con valores faltantes, siempre se debe tener cuidado de no alterar significativamente las características estructurales de los datos originales. Una forma sencilla de verificar que nuestros datos mantienen su estructura general a través del resumen estadístico de los datos antes y después de que se completen los valores faltantes.

```{r}
summary(datos)
```

# Codificación de variables categóricas
```{r}
datos$BAD=factor(datos$BAD, levels = c(0, 1), labels = c("No Moroso", "Moroso"))
contrasts(datos$BAD)
```

```{r}
contrasts(datos$REASON)
```


```{r}
contrasts(datos$JOB)
```


# División de los datos
Hacemos una división del 70% para el conjunto de entrenamiento y del 30% para el conjunto de prueba. Llamamos a los nuevos conjuntos de datos datos_entrenamiento y datos_prueba, respectivamente.
```{r}
set.seed(123) # Para reproducibilidad
indice <- sample(nrow(datos), round(nrow(datos)*0.7), replace = FALSE) # 70% de los datos para entrenamiento
datos_entrenamiento <- datos[indice, ]
datos_prueba <- datos[-indice, ]
```

clases de los conjuntos de datos:
```{r}
round(prop.table(table(select(datos, BAD), exclude = NULL)), 4) * 100
 round(prop.table(table(select(datos_entrenamiento, BAD), exclude = NULL)), 4) * 100
 round(prop.table(table(select(datos_prueba, BAD), exclude = NULL)), 4) * 100
```

# Regresión logística

```{r}
# Ajuste del modelo de regresion logistica
modelo_logistico <- glm(BAD ~ ., data=datos_entrenamiento, family=binomial)
summary(modelo_logistico)
```

```{r}
exp(coef(modelo_logistico))
```

```{r}
tidy(modelo_logistico)
```

Los resultados muestran que las variables JOBOffice,DEROG,DELINQ,CLAGE y DEBTINC en el modelo son estadísticamente significativas a un nivel de confianza alpha =0.05.

```{r}
vip(modelo_logistico,num_features=18)
```

```{r}
logistica_1 <- glm(BAD ~ LOAN + MORTDUE + VALUE + REASON + JOB + YOJ + DEROG + DELINQ + CLAGE + NINQ + CLNO, data = datos_entrenamiento, family = "binomial")

summary(logistica_1)

```

```{r}
# Realizar predicciones con el modelo ya entrenado
logistica_pred = predict(modelo_logistico, type = "response", newdata = datos_prueba)

df_pred = data.frame(BAD = datos_prueba$BAD, Probabilidad = logistica_pred)
tf = table(round(modelo_logistico$fitted.values,2))

logistica_roc <- roc(datos_prueba$BAD, logistica_pred, plot = TRUE, 
                     xlab = "Proporción Falsos Positivos",
                     ylab = "Proporción Verdaderos Positivos", col = "pink", lwd = 2,
                     print.auc = TRUE, legacy.axes = TRUE) 
```


```{r}
roc_data <- roc(datos_prueba$BAD, logistica_pred)

# Umbral óptimo
umbral_optimo <- coords(roc_data, "best", ret = "threshold", best.method = "youden") #0.1428537


# Obtener las medidas de evaluación
medidas <- coords(roc_data, ret = c("threshold", "accuracy", "specificity", "sensitivity", "youden", "tp", "tn", "fp", "fn"))
```


```{r}
predicciones_prob <- predict (modelo_logistico , newdata = datos_prueba , type = "response")
umbral_optimo <- 0.1428537
predicciones <- factor ( ifelse (predicciones_prob > umbral_optimo , " moroso ", "no moroso ") )
# Crear la matriz de confusión
matriz_confusion <- table (datos_prueba $BAD , predicciones , dnn = c(" observaciones", " predicciones ") )

# Reordenar las filas para que la primera casilla de la matriz sea "moroso,moroso"
matriz_confusion_reordenada <- matriz_confusion[c("Moroso", "No Moroso"), ]

# Mostrar la matriz de confusion reordenada
print("Matriz de confusión reordenada:")
print(matriz_confusion_reordenada)
```




Realizamos un modelo logístico solo con las variables significativas veamos así cual es mejor también, pues cuantas menos variables más simple es el modelo. Veamos la calidad de este:
```{r}
# Crear una nueva variable indicadora para JOBOffice
datos_significativa <- datos %>%
  mutate(JOBOffice = ifelse(JOB == "Office", 1, 0))

# Verificar la creación de la nueva variable
head(datos_significativa)
```

Realizamos division de datos para los nuevos datos
```{r}
set.seed(123) # Para reproducibilidad
indice_significativa <- sample(nrow(datos_significativa), round(nrow(datos)*0.7), replace = FALSE) # 70% de los datos para entrenamiento
datos_entrenamiento_significativa <- datos_significativa[indice, ]
datos_prueba_significativa <- datos_significativa[-indice, ]
```


```{r}
modelo_logistico_significativa <- glm(BAD ~ JOBOffice + DEROG + DELINQ + CLAGE + DEBTINC, data = datos_entrenamiento_significativa, family = "binomial")

summary(modelo_logistico_significativa)


logistica_pred_significativa = predict(modelo_logistico_significativa, type = "response", newdata = datos_prueba_significativa)

df_pred = data.frame(BAD = datos_prueba_significativa$BAD, Probabilidad = logistica_pred_significativa)
tf = table(round(modelo_logistico$fitted.values,2))

logistica_roc_significativa <- roc(datos_prueba$BAD, logistica_pred, plot = TRUE, 
                     xlab = "Proporción Falsos Positivos",
                     ylab = "Proporción Verdaderos Positivos", col = "pink", lwd = 2,
                     print.auc = TRUE, legacy.axes = TRUE) 
```



```{r}
roc_data_significativa <- roc(datos_prueba_significativa$BAD, logistica_pred_significativa)

# Umbral óptimo
umbral_optimo_significativa <- coords(roc_data_significativa, "best", ret = "threshold", best.method = "youden") #0.1428537


# Obtener las medidas de evaluación
medidas_significativa <- coords(roc_data_significativa, ret = c("threshold", "accuracy", "specificity", "sensitivity", "youden", "tp", "tn", "fp", "fn"))
```


```{r}
predicciones_prob_significativa <- predict (modelo_logistico_significativa , newdata = datos_prueba_significativa , type = "response")
umbral_optimo_significativa <- 0.1419092
predicciones_significativa <- factor ( ifelse (predicciones_prob_significativa > umbral_optimo_significativa , " moroso ", "no moroso ") )
# Crear la matriz de confusión
matriz_confusion_significativa <- table (datos_prueba_significativa$BAD , predicciones_significativa , dnn = c(" observaciones", " predicciones ") )

# Reordenar las filas para que la primera casilla de la matriz sea "moroso,moroso"
matriz_confusion_reordenada_significativa <- matriz_confusion_significativa[c("Moroso", "No Moroso"), ]

# Mostrar la matriz de confusión reordenada
print("Matriz de confusión reordenada:")
print(matriz_confusion_reordenada_significativa)
```




# Redes neuronales
```{r}
# Ajuste del modelo de redes neuronales
set.seed(123)
modelo_nnet <- nnet(BAD ~ LOAN + MORTDUE + VALUE + REASON + JOB + YOJ + DEROG + DELINQ + CLAGE + NINQ + CLNO + DEBTINC, data=datos_entrenamiento, size=10, maxit=200, decay=0.05)

# Predicciones con el modelo de redes neuronales
predicciones_nnet <- predict(modelo_nnet, datos_prueba, type="class")

# Matriz de confusión del modelo de redes neuronales en los datos de prueba
matriz_confusion_nnet <- table(predicciones_nnet, datos_prueba$BAD)
print(matriz_confusion_nnet)
```


```{r}
prediccion_nnet <- predict(modelo_nnet, datos_prueba, type="raw")
nnet_roc= roc(datos_prueba$BAD, prediccion_nnet, plot = TRUE, 
               xlab = "Proporcion Falsos Positivos",
    ylab = "Proporcion Verdaderos Postivios", col = "pink", lwd = 2,
    print.auc = TRUE, legacy.axes = TRUE) 
```

```{r}
# Ajuste del modelo de redes neuronales
set.seed(123) # Para reproducibilidad
modelo_nnet1 <- nnet(BAD ~ LOAN + MORTDUE + VALUE + REASON + JOB + YOJ + DEROG + DELINQ + CLAGE + NINQ + CLNO + DEBTINC, data=datos_entrenamiento, size=10, maxit=300, decay=0.45)

# Predicciones con el modelo de redes neuronales
predicciones_nnet1 <- predict(modelo_nnet1, datos_prueba, type="class")

# Matriz de confusión del modelo de redes neuronales en los datos de prueba
matriz_confusion_nnet1 <- table(predicciones_nnet1, datos_prueba$BAD)
print(matriz_confusion_nnet1)

# Reordenar las filas para que la primera casilla de la matriz sea "moroso,moroso"
matriz_confusion_nnet1_reordenada <- matriz_confusion_nnet1[c("Moroso", "No Moroso"), ]

# Mostrar la matriz de confusión reordenada
print("Matriz de confusión reordenada:")
print(matriz_confusion_nnet1_reordenada)
```

```{r}
prediccion_nnet1 <- predict(modelo_nnet1, datos_prueba, type="raw")
nnet_roc1= roc(datos_prueba$BAD, prediccion_nnet1, plot = TRUE, 
               xlab = "Proporcion Falsos Positivos",
    ylab = "Proporcion Verdaderos Postivios", col = "pink", lwd = 2,
    print.auc = TRUE, legacy.axes = TRUE) 
```

```{r}
# Gráficos comparativos
ggplot(datos_prueba, aes(x = DEBTINC, y=BAD))+
  geom_point(color = "blue", alpha = 0.5) +
  geom_line(aes(y = predicciones_prob), color = "red", size = 1) +
  geom_line(aes(y = prediccion_nnet), color = "green", size = 1) +
  labs(title = "Comparación de Predicciones: Regresión Logística vs Red Neuronal",
       x = "DEBTINC",
       y = "Probabilidad Predicha de BAD") +
  theme_minimal()


ggplot(datos_prueba, aes(x = DEBTINC, y=BAD))+
  geom_point(color = "blue", alpha = 0.5) +
  geom_line(aes(y = predicciones_prob), color = "red", size = 1) +
  geom_line(aes(y = prediccion_nnet1), color = "green", size = 1) +
  labs(title = "Comparación de Predicciones: Regresión Logística vs Red Neuronal",
       x = "DEBTINC",
       y = "Probabilidad Predicha de BAD") +
  theme_minimal()
```

